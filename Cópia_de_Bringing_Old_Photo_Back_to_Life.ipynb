{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frbruno/Bringing-Old-Photos-Back-to-Life/blob/master/C%C3%B3pia_de_Bringing_Old_Photo_Back_to_Life.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkkr1Sq6t2lM"
      },
      "source": [
        "#◢ Bringing Old Photos Back to Life"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypb6kal06Tb1"
      },
      "source": [
        "This is a reference implementation of our CVPR 2020 paper [1], which  revives an old photo to modern style. Should you be making use of our work, please cite our paper [1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwXBx7z6rfXK"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#◢ Verify Runtime Settings\n",
        "\n",
        "**<font color='#FF000'> IMPORTANT </font>**\n",
        "\n",
        "In the \"Runtime\" menu for the notebook window, select \"Change runtime type.\" Ensure that the following are selected:\n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMZ2EAlBrvkq"
      },
      "source": [
        "#◢ Git clone\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69H2guBfrzqu",
        "outputId": "e351f037-d4de-4251-8fe1-0a12f51885c9"
      },
      "source": [
        "!git clone https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life.git photo_restoration"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'photo_restoration'...\n",
            "remote: Enumerating objects: 509, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 509 (delta 108), reused 100 (delta 100), pack-reused 362\u001b[K\n",
            "Receiving objects: 100% (509/509), 40.89 MiB | 24.09 MiB/s, done.\n",
            "Resolving deltas: 100% (235/235), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubc05fcKzk90"
      },
      "source": [
        "#◢ Set up the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32jCofdSr8AW",
        "outputId": "28f8ee0a-4344-4e5e-af9a-ba0f9a581ebb"
      },
      "source": [
        "# pull the syncBN repo\n",
        "%cd photo_restoration/Face_Enhancement/models/networks\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../../\n",
        "\n",
        "%cd Global/detection_models\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../\n",
        "\n",
        "# download the landmark detection model\n",
        "%cd Face_Detection/\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n",
        "%cd ../\n",
        "\n",
        "# download the pretrained model\n",
        "%cd Face_Enhancement/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\n",
        "!unzip checkpoints.zip\n",
        "%cd ../\n",
        "\n",
        "%cd Global/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\n",
        "!unzip checkpoints.zip\n",
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/photo_restoration/Face_Enhancement/models/networks\n",
            "Cloning into 'Synchronized-BatchNorm-PyTorch'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 188 (delta 10), reused 27 (delta 10), pack-reused 161\u001b[K\n",
            "Receiving objects: 100% (188/188), 47.20 KiB | 671.00 KiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Global/detection_models\n",
            "Cloning into 'Synchronized-BatchNorm-PyTorch'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 188 (delta 10), reused 27 (delta 10), pack-reused 161\u001b[K\n",
            "Receiving objects: 100% (188/188), 47.20 KiB | 4.72 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Face_Detection\n",
            "--2024-01-05 04:20:58--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  28.0MB/s    in 2.2s    \n",
            "\n",
            "2024-01-05 04:21:00 (28.0 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Face_Enhancement\n",
            "--2024-01-05 04:21:10--  https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\n",
            "Resolving facevc.blob.core.windows.net (facevc.blob.core.windows.net)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘facevc.blob.core.windows.net’\n",
            "unzip:  cannot find or open checkpoints.zip, checkpoints.zip.zip or checkpoints.zip.ZIP.\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Global\n",
            "--2024-01-05 04:21:10--  https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\n",
            "Resolving facevc.blob.core.windows.net (facevc.blob.core.windows.net)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘facevc.blob.core.windows.net’\n",
            "unzip:  cannot find or open checkpoints.zip, checkpoints.zip.zip or checkpoints.zip.ZIP.\n",
            "/content/photo_restoration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3v8tvmtw85c",
        "outputId": "a1168651-d6e7-4cb1-f08f-6a882ecad967"
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.16.0+cu121)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (19.24.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.19.3)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.11)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (6.0.1)\n",
            "Collecting dominate>=2.3.1 (from -r requirements.txt (line 7))\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Collecting dill (from -r requirements.txt (line 8))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX (from -r requirements.txt (line 9))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.8.0.76)\n",
            "Collecting einops (from -r requirements.txt (line 12))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PySimpleGUI (from -r requirements.txt (line 13))\n",
            "  Downloading PySimpleGUI-4.60.5-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 4)) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 9)) (3.20.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 14)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 14)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 14)) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 14)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 14)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 14)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 14)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: PySimpleGUI, tensorboardX, einops, dominate, dill\n",
            "Successfully installed PySimpleGUI-4.60.5 dill-0.3.7 dominate-2.9.1 einops-0.7.0 tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soHBzgRU8rPY"
      },
      "source": [
        "#◢ Run the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVpoONmCcJDt"
      },
      "source": [
        "### Restore photos (normal mode)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6lNy6jw5rjd",
        "outputId": "7d5780dd-2ba7-4243-8abd-cfbb8e7c92aa"
      },
      "source": [
        "%cd /content/photo_restoration/\n",
        "input_folder = \"test_images/old\"\n",
        "output_folder = \"output\"\n",
        "\n",
        "import os\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "!python run.py --input_folder /content/photo_restoration/test_images/old --output_folder /content/photo_restoration/output/ --GPU 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/photo_restoration\n",
            "Running Stage 1: Overall restoration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yeeDiM4exHz"
      },
      "source": [
        "import io\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "    a = np.asarray(a, dtype=np.uint8)\n",
        "    data = io.BytesIO()\n",
        "    PIL.Image.fromarray(a).save(data, format)\n",
        "    im_data = data.getvalue()\n",
        "    try:\n",
        "      disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "    except IOError:\n",
        "      if jpeg_fallback and format != 'jpeg':\n",
        "        print(('Warning: image was too large to display in format \"{}\"; '\n",
        "              'trying jpeg instead.').format(format))\n",
        "        return imshow(a, format='jpeg')\n",
        "      else:\n",
        "        raise\n",
        "    return disp\n",
        "\n",
        "def make_grid(I1, I2, resize=True):\n",
        "    I1 = np.asarray(I1)\n",
        "    H, W = I1.shape[0], I1.shape[1]\n",
        "\n",
        "    if I1.ndim >= 3:\n",
        "        I2 = np.asarray(I2.resize((W,H)))\n",
        "        I_combine = np.zeros((H,W*2,3))\n",
        "        I_combine[:,:W,:] = I1[:,:,:3]\n",
        "        I_combine[:,W:,:] = I2[:,:,:3]\n",
        "    else:\n",
        "        I2 = np.asarray(I2.resize((W,H)).convert('L'))\n",
        "        I_combine = np.zeros((H,W*2))\n",
        "        I_combine[:,:W] = I1[:,:]\n",
        "        I_combine[:,W:] = I2[:,:]\n",
        "    I_combine = PIL.Image.fromarray(np.uint8(I_combine))\n",
        "\n",
        "    W_base = 600\n",
        "    if resize:\n",
        "      ratio = W_base / (W*2)\n",
        "      H_new = int(H * ratio)\n",
        "      I_combine = I_combine.resize((W_base, H_new), PIL.Image.LANCZOS)\n",
        "\n",
        "    return I_combine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Eo4Hjti7Nh"
      },
      "source": [
        "filenames = os.listdir(os.path.join(input_path))\n",
        "filenames.sort()\n",
        "\n",
        "for filename in filenames:\n",
        "    print(filename)\n",
        "    image_original = PIL.Image.open(os.path.join(input_path, filename))\n",
        "    image_restore = PIL.Image.open(os.path.join(output_path, 'final_output', filename))\n",
        "\n",
        "    display(make_grid(image_original, image_restore))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSUF96UgTuwd"
      },
      "source": [
        "### Restore the photos with scratches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-yb3lO5T8aM"
      },
      "source": [
        "!rm -rf /content/photo_restoration/output/*\n",
        "!python run.py --input_folder /content/photo_restoration/test_images/old_w_scratch/ --output_folder /content/photo_restoration/output/ --GPU 0 --with_scratch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSSORPEMUSH0"
      },
      "source": [
        "input_folder = \"test_images/old_w_scratch\"\n",
        "output_folder = \"output\"\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "\n",
        "filenames = os.listdir(os.path.join(input_path))\n",
        "filenames.sort()\n",
        "\n",
        "for filename in filenames:\n",
        "    print(filename)\n",
        "    image_original = PIL.Image.open(os.path.join(input_path, filename))\n",
        "    image_restore = PIL.Image.open(os.path.join(output_path, 'final_output', filename))\n",
        "\n",
        "    display(make_grid(image_original, image_restore))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMnje_NWj24x"
      },
      "source": [
        "#◢ Try it on your own photos!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vov9hg957-D"
      },
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "upload_path = os.path.join(basepath, \"test_images\", \"upload\")\n",
        "upload_output_path = os.path.join(basepath, \"upload_output\")\n",
        "\n",
        "if os.path.isdir(upload_output_path):\n",
        "    shutil.rmtree(upload_output_path)\n",
        "\n",
        "if os.path.isdir(upload_path):\n",
        "    shutil.rmtree(upload_path)\n",
        "\n",
        "os.mkdir(upload_output_path)\n",
        "os.mkdir(upload_path)\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(os.path.join(basepath, filename), os.path.join(upload_path, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy9vSWTHMH5U"
      },
      "source": [
        "Run the processing with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgRUwTqsjr7m"
      },
      "source": [
        "!python run.py --input_folder /content/photo_restoration/test_images/upload --output_folder /content/photo_restoration/upload_output --GPU 0 --with_scratch --HR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lEXtwXpLl1L"
      },
      "source": [
        "### Visualize\n",
        "\n",
        "Now you have all your results under the folder `upload_output` and you can *manually* right click and download them.\n",
        "\n",
        "Here we use the child photos of celebrities from https://www.boredpanda.com/childhood-celebrities-when-they-were-young-kids/?utm_source=google&utm_medium=organic&utm_campaign=organic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvqDOPXnLmkl"
      },
      "source": [
        "filenames_upload = os.listdir(os.path.join(upload_path))\n",
        "filenames_upload.sort()\n",
        "\n",
        "filenames_upload_output = os.listdir(os.path.join(upload_output_path, \"final_output\"))\n",
        "filenames_upload_output.sort()\n",
        "\n",
        "for filename, filename_output in zip(filenames_upload, filenames_upload_output):\n",
        "    image_original = PIL.Image.open(os.path.join(upload_path, filename))\n",
        "    image_restore = PIL.Image.open(os.path.join(upload_output_path, \"final_output\", filename_output))\n",
        "\n",
        "    display(make_grid(image_original, image_restore))\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2B75ztFYnnK"
      },
      "source": [
        "## Download your results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pJxB6p1R1jE"
      },
      "source": [
        "output_folder = os.path.join(upload_output_path, \"final_output\")\n",
        "print(output_folder)\n",
        "os.system(f\"zip -r -j download.zip {output_folder}/*\")\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFXuH9qd5u9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}